\documentclass[12pt, a4paper]{article} %minska pointen om du vill ha mindre bokstäver

\usepackage[english]{babel}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc} 	

\usepackage{amsmath}	% Om du vill använda AMSLaTeX 
\usepackage{amssymb}	% Om du vill använda AMS symboler
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage[hidelinks]{hyperref}
\usepackage{tikz} % för tikz-figurer
\usepackage{pgfplots}
\usepackage{csvsimple}
\usepackage{booktabs}

\pgfplotsset{width=0.75\textwidth,compat=1.9}
\usepgfplotslibrary{statistics}

\usepackage[parfill]{parskip}

\usepackage{subcaption} % för flera figurer i en

% Färger för exempelkoden
\usepackage{xcolor}
\definecolor{backcol}{gray}{0.95} % bakgrundfärg
\definecolor{darkpastelgreen}{rgb}{0.01, 0.75, 0.24} % bl.a. kommentarer i koden

\usepackage{listings} % för exempelkod
% Inställningar
\lstset{
	basicstyle=\ttfamily\scriptsize, % monospace, mindre bokstäver
	basewidth  = {.5em,0.5em}, % minskar avståndet mellan bokstäverna (passar fonten)
	numbers=left, numberstyle=\tiny, 
	frame=tb, % streck top och bottom
	breaklines=true, % radbyte vid behov
	backgroundcolor = \color{backcol},
	keywordstyle=\color{blue}, 
	commentstyle=\color{darkpastelgreen},
	captionpos=t,
	framexleftmargin=2mm, % padding
	xleftmargin=2mm, % lägg till marginal för att hållas i linje med texten
	framexrightmargin=2mm,
	xrightmargin=2mm,
	}

\title{Operating systems -- Assignment 2\\Scheduling}

\author{Lennart Jern\\
	CS: ens16ljn\\ \\ \textbf{Teacher}\\ Ahmed Aley}


\begin{document}


\maketitle

\newpage


\section{Introduction}

The Linux kernel provides a number of different scheduling policies that can be used to fine tune the performance of certain applications.
In this report, five different schedulers are evaluated using an artificial, CPU intensive, task.
Three of the tested schedulers are ``normal'', while the last two are ``real-time'' schedulers, meaning that they provide higher priority for their processes than the normal ones do.

The work load consists of a simple program, called \texttt{work}, that sums over a part of Grandi's series\footnote{\url{https://en.wikipedia.org/wiki/Grandi's_series}} ($1-1+1-1+\dots$), using a specified number of threads.
The source code for \texttt{work} can be found in listing \ref{work}.
Since the task is easy to parallelize, only require minimal memory access and no disk access, it should be comparable to CPU intense tasks like compression and matrix calculations.

\section{Method}

A Bash script (\texttt{timer.sh}, listing \ref{timer}) was used to time the complete task 10 times for each scheduler, for thread counts ranging from 1 to 10.
See code listing \ref{timer} for the code.
Additionally, each thread keeps track of the time taken from the start of its execution until it is finished, and prints this information to \texttt{stdout}, which is forwarded to data files by the bash script.

All this data was then processed by a simple Python program, \texttt{stats}, in order to calculate the median, minimum and maximum run time for each scheduler and thread count; for both the total run times and the individual thread times.
This program can be found in listing \ref{stats}.
In addition to the statistical calculations, \texttt{stats} also produces some figures to describe the data.
The figures and calculations are mostly done using the python libraries Pandas\footnote{\url{http://pandas.pydata.org/}} and Matplotlib\footnote{\url{http://matplotlib.org/}}.

It should be noted here that the processes running with real-time schedulers were run with maximum priority.
Since the other schedulers does not accept a priority setting, other than the nice value, these were left untouched.

All tests were run on my personal computer with the specifications seen in table \ref{spec}.

\begin{table}[h]
	\centering
	\begin{tabular}{ll}
		Component & Specification \\
		\hline
		OS: & Fedora 25 \\
		Kernel: & Linux 4.8.13-300.fc25.x86\_64 \\
		CPU: & Intel Core i5-2500K CPU @ 3.7GHz \\
		RAM: & 7965MiB \\
		GCC: & 6.2.1 \\
		Bash: & 4.3.43 \\
		Python: & 3.5.2 \\
		Pandas: & 0.18.1 \\
		Matplotlib: & 1.5.3
	\end{tabular}
	\caption{Test system specification.}
	\label{spec}
\end{table}



\section{Results}

For the total run time of the process, there does not seem to be much of a difference between the five schedulers (see fig. \ref{median-total}).
This is perhaps not too surprising considering that the system was practically idle, except for the work load process, so this process naturally got all resources the system could offer.

\input{total-median.tex}

More interesting is the range (difference between maximum and minimum) of response times for the total run time of the process (fig. \ref{range}).
This reveals a clear difference between the real-time and normal schedulers, where the real-time ones are clearly more predictable for two or more threads.

\input{range.tex}

The same trend can also be seen for the thread response times in fig. \ref{thread-range}.
Furthermore, there is a small difference in median run time for the schedulers, when looking at the individual thread times, for a thread count between 6 and 8.
This can be seen in fig. \ref{threads-medians}, where the Batch scheduler have a lower median time than the others.
However, the difference seem to be somewhat periodic and vanishes almost completely with 9 threads.
The Round Robin scheduler also follows this pattern but with a shorter period.
With the exception of Batch, Round Robin beats the other schedulers for thread counts of 5, 6, 9 and 10.

\input{thread-range.tex}
\input{threads-median.tex}

The differences are even clearer when looking at the box charts for the individual thread times in figures \ref{box1} and \ref{box2} where the range between the maximum and minimum run times can also be seen.

\input{box.tex}

To further analyze the behavior of the schedulers, we can take a look at the density plots for the thread times in figures \ref{density1} and \ref{density2}.
There are only small differences when running with two threads.
But with four threads instead, we can see that the Batch scheduler have two distinct ``batches'' while RR is much closer to have all threads finish in one lump.
I am quite surprised to see the FIFO curve so flat and spread out at four threads, since they should all be able to run together and finish simultaneously.

\input{density.tex}

At six and eight threads, a pattern emerges where the Normal, Idle and FIFO schedulers finishes all their threads close together, while the Batch and RR schedulers both have two groups of threads finishing together.
With a higher resolution we would probably se two peaks for FIFO also, a small bump is already visible in the plots for six and eight threads.

The results for Round Robin follow the theory nicely, as it becomes more and more flat as the thread count increases (compare the figures for six and eight threads), since it tries to distribute the CPU time as evenly as possible.
The Batch scheduler avoids switching between threads, and should thus get one batch of four and one of two threads finishing together when running with six threads total (since the processor has four cores).
With eight threads, there should be two equal batches instead, and this is exactly what we can se in figures \ref{dens6} and \ref{dens8}.
FIFO should in theory get two distinct peaks, but the resolution in the data does not seem to be high enough for this to appear.

\section{Final thoughts and lessons learned}

It is quite clear that it is possible to spend a considerable amount of time just analyzing schedulers.
The results are intriguing as they show clear differences in the behavior between the schedulers, and with several different tasks to compare, even more patterns would surely emerge.

A lesson learned is that one should think carefully about when and where to start and stop the timers.
If measuring just the whole task, this is quite easy, but for the individual threads it gets more tricky.
The thread that starts the other threads must also start the timers since the working thread may not get to start immediately.
Similarly, the working threads must stop their own timers, since there might be a pause between the threads finishing and actually getting joined.

\clearpage
\appendix

\section{Code listings}

\lstinputlisting[language=c, caption=work.c, label=work]{../code/work.c}

\lstinputlisting[language=bash, caption=timer.sh, label=timer]{../code/timer.sh}

\lstinputlisting[language=python, caption=stats.py, label=stats]{../code/stats.py}

%\lstinputlisting[caption=Makefile, label=make]{../code/Makefile}

%\section{Raw data}\label{raw}

%\csvautobooktabular{data/medians.csv}

%\csvautobooktabular{data/max.csv}

%\csvautobooktabular{data/min.csv}

%\csvautobooktabular{data/data1.csv}
%\csvautobooktabular{data/data2.csv}
%\csvautobooktabular{data/data3.csv}
%\csvautobooktabular{data/data4.csv}
%\csvautobooktabular{data/data5.csv}
%\csvautobooktabular{data/data6.csv}
%\csvautobooktabular{data/data7.csv}
%\csvautobooktabular{data/data8.csv}
%\csvautobooktabular{data/data9.csv}
%\csvautobooktabular{data/data10.csv}

\end{document}
